\chapter{GCN Model}

In modern Machine Learning, a popular type of Neural Network is a Convolutional Neural Network. Such networks generally operate on grids. A Convolutional Neural Network (CNN) has a fixed node ordering -- some input must firstly be mapped into a grid to be used with a CNN. There are ways to map many types of data into such format. Examples of researchers using CNNs for keystroke dynamics data include Sharma et al. \cite{Shar2023} or Lu et al. \cite{Lu2020}. In Lu et al. this involved applying the convolution layers over feature vectors, which were constructed in the following manner: for pairs of keys pressed in succesion in the sequence, a feature vector is created with fields: ID of first key, ID of second key, hold duration of first key, hold duration of second key, DD time (time between first press and second press) and DU time (time between first press and second release). After applying the CNN layer, GRU layers were used.

In this project, the goal was to use the graph networks that can naturally arise from keystroke data to -- on a graph level -- try to infere the users identity. The main difference was that the use of any keyboard already installed on the user's mobile phone causes some problems with gathering keystroke temporal data, as mentioned in the second chapter. Because of that, this project used mappings involving only key ...

Moreover, this project focused on creating an collection of models, one model for each user that performs binary classification rather than one large model for multiclass classification. 
This decision was made for several reasons. Firstly, such scheme allows for models to be trained on demand, as soon as a new user provides all the training data to the mobile application. Secondly, new users do not force the whole model to be retrained, 
as only one new model needs to be created, and provided all models have learned their target users sufficiently, they would be able to reject such new users without further tuning. Lastly, the one user per model scheme allows for inference to take place locally, on the target user's device. This would remove the need for remote communication with the server, thus increasing the mobile application's reliability and security. On device inference is an area of active research, such as \myworries{TODO citation needed}, the complexity of such solution was deemed to great and outside the scope of this project.
