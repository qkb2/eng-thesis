
\chapter{Graph Convolutional Networks}

A graph can be defined as mathematical structure $G$ consisting of a set of vertices $V$ and a set of edges $E$, where each edge can be described as an unordered pair $\{ v_1, v_2 \}$ of some vertices $v_1, v_2 \in V$ for undirected graphs or an ordered pair $( v_1, v_2 )$ of some vertices $v_1, v_2 \in V$ \cite{wikipedia_graph_2025}. Such structures, along with their many variations and generalizations, can be used for describing entities, which are related to each other in some way. An example of such a model could be a computer network graph or citation network. Neurons can also be modeled in a similar way. Relation data can often be best described using such graphs \cite{Lesk2024}.

Some problems relating to such data can be solved using Convolutional Neural Networks -- this can also be the case for keystroke dynamics data \cite{Lu2020}\cite{Shar2023}. However, it can be reasoned that Graph Neural Networks can also perform such tasks, with connections in graph data being used more directly in the model itself. Most of the equations and theoretical concepts presented in this chapter are adapted from or based on \cite{Lesk2024}.

\section{Graph Neural Networks}
Graph Neural Networks (GNNs) are designed for graph inputs. The resulting outputs are also graphs (specifically, they are node embeddings representing a graph), allowing for transforming information in the graph's nodes, edges, and global context, such as metadata about the graph, aggregated information, graph features, etc. \cite{sanch2021} GNN do not change the connectivity of the input in the output. 

Graphs in GNNs are represented with two main components: the adjacency matrix $A$ and the matrix of node features $X \in \mathbb{R}^{|V| \times m}$, where $m$ is the number of features for each node. The feature vector for a node can be any data describing it, such as age or gender for a social network graph. GNN models are constructed with layers, where each layer performs processing in the following steps \cite{Lesk2024}:
\begin{itemize}
    \item Message computation: each node computes a message 
        \begin{align}
            m_u^{(l)} = \text{MSG}^{(l)}(h_u^{(l-1)}), \quad u \in N(v) \cup \{v\}
        \end{align}
        where:
        \begin{itemize}
            \item $m_u^{(l)}$ represents the message computed for node $u$ at layer $l$.
            \item $\text{MSG}^{(l)}$ is the message function at layer $l$.
            \item $h_u^{(l-1)}$ is the feature vector of node $u$ from the previous layer $(l-1)$.
            \item $N(v)$ is a set of neighbors of node $v$.
        \end{itemize}
    \item Message aggregation: each node aggregates messages from its neighbors
        \begin{align}
            h_v^{(l)} = \text{AGG}^{(l)}\left(\left\{ m_u^{(l)} : u \in N(v) \right\}, m_v^{(l)}\right)
        \end{align}
        where:
        \begin{itemize}
            \item $h_v^{(l)}$ is the updated feature (embedding) of node $v$ at layer $l$. 
        \end{itemize}
        To prevent losing a message from node $v$ itself, the message from node $v$ is included after aggregating messages from all its neighbors.   
    \item Additionally, an activation function $\phi$ (e.g., ReLU, sigmoid) is applied to the message or the aggregation.
\end{itemize}

For Graph Convolutional Networks message computation and aggregation can be represented with the following formula \cite{Lesk2024}:
\begin{align}
    h_v^{(l)} = \phi \left( \sum_{u \in N(v)} \frac{1}{|N(v)|} W^{(l)} h_u^{(l-1)} \right)
\end{align}
where:
$W^{(l)}$ is a learnable weight matrix used to transform the feature vector.

The optimal number of layers in GCN is usually small \cite{optimal_no_of_layers}\cite{kipf2017}. Adding too many layers does not necessarily improve performance and may even degrade it due to over-smoothing. The number of layers should be selected based on the specific problem and graph structure.

\section{Convolutional Networks and Graph Convolutional Networks}
Convolutional Neural Networks work with grid-like data structures, such as images, where each element (e.g., a pixel) has a defined spatial relationship with its neighbors. An image can be treated as a special type of graph where each pixel is a node connected to its neighboring pixels by edges \cite{sanch2021}\cite{Lesk2024}. This analogy helps in understanding that while CNNs process regular grids with a fixed neighborhood size, they can be seen as a specific case of Graph Neural Networks operating on structured data. This regular structure allows convolutional filters to move systematically across the input, helping to extract different levels of features. As a result, CNNs excel at computer vision tasks. However, graphs do not provide the structured data layout required by CNNs. They can have varying numbers of neighbors and lack a consistent ordering, which makes applying CNNs directly ineffective for graph data.

Graph Convolutional Networks solve this problem by directly handling graph-structured data. Since nodes in graphs do not follow a specific order and can connect to different numbers of neighbors, GCNs use the graph's adjacency matrix to gather information from neighboring nodes. This method focuses on relationships between nodes (who is connected to whom) rather than their exact positions. Consequently, GCNs effectively capture both local and global structures in graphs, making them suitable for tasks like node classification, link prediction, and graph classification.


\section{Graph-level prediction and classification in GNN}
Supervised learning on graphs can be achieved by labeling either nodes, edges, or whole graphs \cite{Lesk2024}. In a typical training pipeline, an input graph is transformed into a node representation accepted by the network, which then transforms the data in the manner described above. Output node embeddings are then used to create a prediction head, which is used, together with labels and some loss function and evaluation metrics, for the prediction task. There are different prediction heads for node-level, edge-level or graph-level prediction \cite{Lesk2024}. For nodes, predictions can be made directly using node embeddings -- this can be done by using a classification layer, like a dense layer followed by a Softmax layer \cite{sanch2021}.  For the edges, this must be done on pairs of nodes. For global graph predictions, a pooling of node embeddings can be performed. Options for pooling include for example global mean pooling, global max pooling or global sum pooling. For classification purposes, which can be thought as a k-way prediction task, node-level classification can be achieved via cross-entropy (CE) loss function for i-th example in training \cite{Lesk2024}:
\begin{align}
    \text{CE}({\mathbf{y}}^{(i)}, {\hat{\mathbf{y}}}^{(i)}) = -\sum_{j=1}^{K} {\mathbf{y}}_{j}^{(i)} \log({\hat{\mathbf{y}}}_{j}^{(i)})
\end{align}
where:
\begin{itemize}
    \item $K$ is the number of classes
    \item ${\mathbf{y}}^{(i)}$ is a one-hot label encoding
    \item ${\hat{\mathbf{y}}}^{(i)}$ is a prediction after Softmax
\end{itemize}
Total loss over the training examples can then be calculated as a sum of cross-entropy for each example.